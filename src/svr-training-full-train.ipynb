{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Testing SVR Regression on Retrieval Task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3031628/1415649699.py:16: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "import torch, torch.nn.functional as F\n",
    "import os\n",
    "import gc \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import cudf\n",
    "import cuml\n",
    "import numba.cuda\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import cdist\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.manifold import TSNE\n",
    "from heapq import nlargest\n",
    "from io import StringIO\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cuml.svm import SVR as cumlSVR\n",
    "from cuml.preprocessing import StandardScaler as cumlStandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "[<torch.cuda.device object at 0x7f7f0e76f310>, <torch.cuda.device object at 0x7f7f0e76fe80>]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "print(device)\n",
    "print(available_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    GERDALIR_PATH = './data/GerDaLIR/'\n",
    "    EMBEDDINGS_DIRECTORY = './data/embeddings/'\n",
    "    COMBINED_EMBEDDINGS = './data/embeddings/combined_{TYPE}_.npy'\n",
    "    REMOVE_STOPWORDS = False\n",
    "    EPXLODE_SENTENCES = True\n",
    "    USE_TFIDF = False\n",
    "    CHUNK_QUERIES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf8') as file:\n",
    "        for line in file:\n",
    "            columns = line.strip().split('\\t')\n",
    "            # Concatenate columns from index 1 onwards (since we have some broken rows)\n",
    "            concatenated_value = ''.join(columns[1:])\n",
    "            data.append((columns[0], concatenated_value))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['id', 'value'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = read_tsv(Config.GERDALIR_PATH + 'collection/collection.tsv').head(99900000)\n",
    "collection.rename(columns={'id': 'd_id', 'value':'passage'}, inplace=True)\n",
    "collection.reset_index(inplace=True)\n",
    "\n",
    "rels = read_tsv(Config.GERDALIR_PATH + 'qrels/qrels.train.tsv')\n",
    "rels.rename(columns={'id': 'q_id', 'value': 'd_id'}, inplace=True)\n",
    "rels = rels[rels['d_id'].isin(collection['d_id'].values)] # This can be deleted once we work with all\n",
    "rels.reset_index(inplace=True)\n",
    "\n",
    "queries = read_tsv(Config.GERDALIR_PATH + 'queries/queries.train.tsv')\n",
    "queries.rename(columns={'id': 'q_id', 'value': 'query'}, inplace=True)\n",
    "queries = queries[queries['q_id'].isin(rels['q_id'].values)] # This can be deleted once we work with all\n",
    "queries.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>q_id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Nach [REF] ist eine Erlaubnis zu widerrufen, wenn nachträglich bekannt wird, dass die Voraussetzung nach § 0 Nummer 0 nicht erfüllt ist. Gemäß [REF] setzt die Erlaubnis zum Führen der Berufsbezeichnung voraus, dass die antragstellende Person sich nicht eines Verhaltens schuldig gemacht hat, aus dem sich die Unzuverlässigkeit zur Ausübung des Berufes ergibt. Der gerichtlich voll überprüfbare unbestimmte Rechtsbegriff der Zuverlässigkeit bezeichnet ein Instrument sicherheits und ordnungsrechtlicher Gefahrenabwehr. Der Ausschluss unzuverlässiger Erlaubnisbewerber bzw. inhaber hat demgemäß präventiven Charakter und dient der Abwehr von Gefahren für das Gemeinwohl. Unzuverlässigkeit i. S. d. der Bestimmungen ist dabei in Anlehnung an entsprechende Begrifflichkeiten in anderen, auch heilberufsrechtlichen Bestimmungen anzunehmen, wenn bei prognostischer Betrachtung auf Grund einer Würdigung der gesamten Persönlichkeit, des Gesamtverhaltens und der Lebensumstände des Betreffenden unter Berücksichtigung der Eigenart des Berufs nicht die Gewähr besteht, dass dieser in Zukunft seine beruflichen Pflichten zuverlässig erfüllen wird. Für die gebotene Prognose ist dabei abzustellen auf die jeweilige Situation des Betreffenden im maßgeblichen Zeitpunkt, der regelmäßig im Abschluss des behördlichen Verfahrens liegt, sowie auf vor allem durch die Art, Schwere und Zahl der Verstöße gegen die Berufspflichten manifest gewordenen Charakter des Betreffenden.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Erforderlich ist mithin eine Prognoseentscheidung unter Berücksichtigung aller Umstände des Einzelfalls dahingehend, ob der Betreffende willens und in der Lage sein wird, künftig seine beruflichen Pflichten zuverlässig zu erfüllen.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index q_id  \\\n",
       "0      0    2   \n",
       "1      1    3   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 query  \n",
       "0  Nach [REF] ist eine Erlaubnis zu widerrufen, wenn nachträglich bekannt wird, dass die Voraussetzung nach § 0 Nummer 0 nicht erfüllt ist. Gemäß [REF] setzt die Erlaubnis zum Führen der Berufsbezeichnung voraus, dass die antragstellende Person sich nicht eines Verhaltens schuldig gemacht hat, aus dem sich die Unzuverlässigkeit zur Ausübung des Berufes ergibt. Der gerichtlich voll überprüfbare unbestimmte Rechtsbegriff der Zuverlässigkeit bezeichnet ein Instrument sicherheits und ordnungsrechtlicher Gefahrenabwehr. Der Ausschluss unzuverlässiger Erlaubnisbewerber bzw. inhaber hat demgemäß präventiven Charakter und dient der Abwehr von Gefahren für das Gemeinwohl. Unzuverlässigkeit i. S. d. der Bestimmungen ist dabei in Anlehnung an entsprechende Begrifflichkeiten in anderen, auch heilberufsrechtlichen Bestimmungen anzunehmen, wenn bei prognostischer Betrachtung auf Grund einer Würdigung der gesamten Persönlichkeit, des Gesamtverhaltens und der Lebensumstände des Betreffenden unter Berücksichtigung der Eigenart des Berufs nicht die Gewähr besteht, dass dieser in Zukunft seine beruflichen Pflichten zuverlässig erfüllen wird. Für die gebotene Prognose ist dabei abzustellen auf die jeweilige Situation des Betreffenden im maßgeblichen Zeitpunkt, der regelmäßig im Abschluss des behördlichen Verfahrens liegt, sowie auf vor allem durch die Art, Schwere und Zahl der Verstöße gegen die Berufspflichten manifest gewordenen Charakter des Betreffenden.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Erforderlich ist mithin eine Prognoseentscheidung unter Berücksichtigung aller Umstände des Einzelfalls dahingehend, ob der Betreffende willens und in der Lage sein wird, künftig seine beruflichen Pflichten zuverlässig zu erfüllen.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "98380"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>d_id</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Tenor Der Antrag der Klägerin auf Zulassung der Berufung gegen das Urteil des Verwaltungsgerichts Gelsenkirchen vom [DATE] wird abgelehnt. Die Klägerin trägt die Kosten des Zulassungsverfahrens. Der Streitwert wird auch für das Zulassungsverfahren auf 0 Euro festgesetzt. Gründe:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Das Zulassungsvorbringen der Klägerin begründet keine ernstlichen Zweifel an der Richtigkeit des angefochtenen Urteils . Zweifel in diesem Sinn sind anzunehmen, wenn ein einzelner tragender Rechtssatz oder eine einzelne erhebliche Tatsachenfeststellung des Verwaltungsgerichts mit schlüssigen Gegenargumenten in Frage gestellt werden.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index d_id  \\\n",
       "0      0    1   \n",
       "1      1    1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                          passage  \n",
       "0                                                         Tenor Der Antrag der Klägerin auf Zulassung der Berufung gegen das Urteil des Verwaltungsgerichts Gelsenkirchen vom [DATE] wird abgelehnt. Die Klägerin trägt die Kosten des Zulassungsverfahrens. Der Streitwert wird auch für das Zulassungsverfahren auf 0 Euro festgesetzt. Gründe:  \n",
       "1  Das Zulassungsvorbringen der Klägerin begründet keine ernstlichen Zweifel an der Richtigkeit des angefochtenen Urteils . Zweifel in diesem Sinn sind anzunehmen, wenn ein einzelner tragender Rechtssatz oder eine einzelne erhebliche Tatsachenfeststellung des Verwaltungsgerichts mit schlüssigen Gegenargumenten in Frage gestellt werden.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3095383"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>q_id</th>\n",
       "      <th>d_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>118149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>72511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index q_id    d_id\n",
       "0      0    2  118149\n",
       "1      1    3   72511"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "115360"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(queries.head(2))\n",
    "display(len(queries))\n",
    "\n",
    "display(collection.head(2))\n",
    "display(len(collection))\n",
    "\n",
    "display(rels.head(2))\n",
    "display(len(rels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_string_with_overlap(s, k, overlap):\n",
    "    if k <= 0:\n",
    "        raise ValueError(\"Chunk length must be greater than 0\")\n",
    "    if overlap < 0:\n",
    "        raise ValueError(\"Overlap must be non-negative\")\n",
    "    if overlap >= k:\n",
    "        raise ValueError(\"Overlap must be less than chunk length\")\n",
    "    \n",
    "    chunks = []\n",
    "    for i in range(0, len(s), k - overlap):\n",
    "        chunk = s[i:i + k]\n",
    "        chunks.append(chunk)\n",
    "        if len(chunk) < k:\n",
    "            break\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average length of queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.06715795893473\n",
      "1043.171305143322\n"
     ]
    }
   ],
   "source": [
    "print(queries['query'].apply(lambda x: len(x.split())).mean())\n",
    "print(queries['query'].apply(lambda x: len(x)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(Config.CHUNK_QUERIES):\n",
    "    queries['query'] = queries['query'].apply(lambda q: chunk_string_with_overlap(q, 275, 15))\n",
    "    queries = queries.explode('query').reset_index(drop=True)\n",
    "    display(queries.head(10))\n",
    "    print(len(queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state.detach().cpu()\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length, text_col):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_col = text_col\n",
    "        self.max = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.loc[idx, self.text_col]\n",
    "        tokens = self.tokenizer(\n",
    "                text,\n",
    "                None,\n",
    "                add_special_tokens=True,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.max,\n",
    "                return_tensors=\"pt\")\n",
    "        tokens = {k:v.squeeze(0) for k,v in tokens.items()}\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedderContainer:\n",
    "\n",
    "    def __init__(self, model_name, max_length, batch_size, device):\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        self.__model_path = model_name\n",
    "        self.__max_length = max_length\n",
    "        self.__batch_size = batch_size\n",
    "\n",
    "    def init_model(self):\n",
    "        self.__model = AutoModel.from_pretrained(self.__model_path, trust_remote_code=True).to(self.device)  #force_download=True\n",
    "        self.__model.eval()\n",
    "        self.__tokenizer = AutoTokenizer.from_pretrained(self.__model_path, trust_remote_code=True)  #force_download=True\n",
    "\n",
    "    def init_embed_dataset(self, df, text_col):\n",
    "        self.__dataset = EmbedDataset(df, self.__tokenizer, self.__max_length, text_col)\n",
    "        self.__embed_dataloader = torch.utils.data.DataLoader(self.__dataset,\n",
    "                                batch_size=self.__batch_size,\n",
    "                                shuffle=False)\n",
    "        return self.__embed_dataloader\n",
    "\n",
    "    def embed(self, input_ids, attention_mask):\n",
    "        return self.__model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    def dispose(self):\n",
    "        if hasattr(self, '__dataset'):\n",
    "            del self.__dataset\n",
    "        if hasattr(self, '__embed_dataloader'):\n",
    "            del self.__embed_dataloader\n",
    "        if hasattr(self, '__model'):\n",
    "            del self.__model\n",
    "        if hasattr(self, '__tokenizer'):\n",
    "            del self.__tokenizer\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(embedding_container, compute_collection=True, compute_queries=False):\n",
    "\n",
    "    global collection, queries\n",
    "    embedding_container.init_model()\n",
    "\n",
    "    # COMPUTE COLLECTION EMBEDDINGS\n",
    "    all_collection_embeddings = []\n",
    "    if compute_collection:\n",
    "        # Create dataset for collection\n",
    "        embed_dataloader_tr = embedding_container.init_embed_dataset(collection, 'passage')\n",
    "        for batch in tqdm(embed_dataloader_tr,total=len(embed_dataloader_tr)):\n",
    "            input_ids = batch[\"input_ids\"].to(embedding_container.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(embedding_container.device)\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast(enabled=True):\n",
    "                    model_output = embedding_container.embed(input_ids, attention_mask)\n",
    "\n",
    "            sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n",
    "            # Normalize the embeddings\n",
    "            sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "            sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n",
    "            all_collection_embeddings.extend(sentence_embeddings)\n",
    "    all_collection_embeddings = np.array(all_collection_embeddings)\n",
    "\n",
    "    # COMPUTE QUERY EMBEDDINGS\n",
    "    all_query_embeddings = []\n",
    "    if compute_queries:\n",
    "        # Create dataset for query\n",
    "        embed_dataloader_te = embedding_container.init_embed_dataset(queries, 'query')\n",
    "        for batch in embed_dataloader_te:\n",
    "            input_ids = batch[\"input_ids\"].to(embedding_container.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(embedding_container.device)\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast(enabled=True):\n",
    "                    model_output = embedding_container.embed(input_ids, attention_mask)\n",
    "            sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n",
    "            # Normalize the embeddings\n",
    "            sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "            sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n",
    "            all_query_embeddings.extend(sentence_embeddings)\n",
    "    all_query_embeddings = np.array(all_query_embeddings)\n",
    "\n",
    "    # DISPOSE\n",
    "    if 'model_output' in locals():\n",
    "        del model_output\n",
    "    if 'sentence_embeddings' in locals():\n",
    "        del sentence_embeddings\n",
    "    if 'input_ids' in locals():\n",
    "        del input_ids\n",
    "    if 'attention_mask' in locals():\n",
    "        del attention_mask\n",
    "    embedding_container.dispose()\n",
    "\n",
    "    # RETURN EMBEDDINGS\n",
    "    return all_collection_embeddings, all_query_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:1\" # We want to extract embeddings on the second GPU.\n",
    "\n",
    "container = [\n",
    "    #EmbedderContainer('microsoft/deberta-base', 1024, 32, DEVICE),\n",
    "    #EmbedderContainer('microsoft/deberta-large', 1024, 8, DEVICE),\n",
    "    #EmbedderContainer('microsoft/deberta-v3-large', 1024, 8, DEVICE),\n",
    "    EmbedderContainer('allenai/longformer-base-4096', 1024, 32, DEVICE),\n",
    "    #EmbedderContainer('LennartKeller/longformer-gottbert-base-8192-aw512', 1024, 32, DEVICE),\n",
    "    #EmbedderContainer('allenai/longformer-large-4096', 1024, 8, DEVICE),\n",
    "    #EmbedderContainer('google/bigbird-roberta-base', 1024, 32, DEVICE),\n",
    "    #EmbedderContainer('google/bigbird-roberta-large', 1024, 8, DEVICE),\n",
    "\n",
    "    # Sentence Transformers fine-tuned for sentence embeddings:\n",
    "    # EmbedderContainer('sentence-transformers/all-distilroberta-v1', 512, 32, DEVICE), # https://huggingface.co/sentence-transformers/all-distilroberta-v1\n",
    "    # EmbedderContainer('sentence-transformers/msmarco-distilbert-base-v4', 512, 32, DEVICE), # https://huggingface.co/sentence-transformers/msmarco-distilbert-base-v4\n",
    "    #EmbedderContainer('sentence-transformers/all-MiniLM-L6-v2', 384, 64, DEVICE), # https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_collection_embeds = []\n",
    "all_query_embeds = []\n",
    "\n",
    "calculate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'collection_full'))):\n",
    "    all_collection_embeds = np.load(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'collection_full'))\n",
    "    all_query_embeds = np.load(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'query_train'))\n",
    "    calculate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(calculate):\n",
    "    for embedding_container in container:\n",
    "        name = (Config.EMBEDDINGS_DIRECTORY + \n",
    "                'collection_' + \n",
    "                embedding_container.model_name.replace(\"/\", \"_\") + \n",
    "                \".npy\")\n",
    "        \n",
    "        if os.path.exists(name):\n",
    "            print(f\"Loading embeddings for {name}\")\n",
    "            _, query_embed = get_embeddings(embedding_container, compute_collection=False, compute_queries=True)\n",
    "            collection_embed = np.load(name)\n",
    "        else:\n",
    "            print(f\"Computing embeddings for {name}\") \n",
    "            collection_embed, query_embed = get_embeddings(embedding_container, compute_collection=True, compute_queries=True)\n",
    "            np.save(name, collection_embed)\n",
    "        all_collection_embeds.append(collection_embed)\n",
    "        all_query_embeds.append(query_embed)\n",
    "\n",
    "    del collection_embed, query_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(calculate):\n",
    "    all_collection_embeds = np.concatenate(all_collection_embeds,axis=1)\n",
    "    all_query_embeds = np.concatenate(all_query_embeds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3095383, 768)\n",
      "(98380, 768)\n"
     ]
    }
   ],
   "source": [
    "print(all_collection_embeds.shape)\n",
    "print(all_query_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(calculate):\n",
    "    np.save(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'collection_full'), all_collection_embeds)\n",
    "    np.save(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'query_train'), all_query_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "calculate_feat = True\n",
    "\n",
    "if(os.path.exists(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'features'))):\n",
    "    features = np.load(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'features'))\n",
    "    labels = np.load(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'labels'))\n",
    "    calculate_feat = False\n",
    "\n",
    "subsampling_top_k = 50\n",
    "\n",
    "# query_idx_lookup = {qid: idx for idx, qid in enumerate(queries['q_id'])}\n",
    "passage_idx_lookup = {pid: idx for idx, pid in enumerate(collection['d_id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_fits_passage(q_idx, c_idx):\n",
    "    '''Does the given collection index fit to a given query index?'''\n",
    "    q_id = queries.iloc[q_idx]['q_id']\n",
    "    d_id = collection.iloc[c_idx]['d_id']\n",
    "    return len(rels[(rels['q_id'] == q_id) & (rels['d_id'] == d_id)].values) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to cupy arrays for faster GPU cosine sims**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(calculate_feat):\n",
    "    all_query_embeds_cp = cp.asarray(all_query_embeds, dtype=cp.float16) \n",
    "    all_collection_embeds_cp = cp.asarray(all_collection_embeds, dtype=cp.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through queries\n",
    "if(calculate_feat):\n",
    "    for q_idx, row in tqdm(queries.iterrows(), total=len(queries), desc='Processing Queries'):\n",
    "        query_id = row['q_id']\n",
    "        query_embed_cp = all_query_embeds_cp[q_idx]\n",
    "\n",
    "        # Positive samples\n",
    "        positive_indices = set()\n",
    "        rels_for_query = rels[rels['q_id'] == query_id]\n",
    "        for passage_id in rels_for_query['d_id']:\n",
    "            if passage_id in passage_idx_lookup:\n",
    "                passage_idx = passage_idx_lookup[passage_id]\n",
    "                #print('Correct answer:')\n",
    "                #print(collection.iloc[passage_idx]['passage'])\n",
    "                passage_embed_cp = all_collection_embeds_cp[passage_idx]\n",
    "\n",
    "                # Convert CuPy arrays back to NumPy\n",
    "                query_embed_np = cp.asnumpy(query_embed_cp)\n",
    "                passage_embed_np = cp.asnumpy(passage_embed_cp)\n",
    "\n",
    "                # Concatenate using NumPy\n",
    "                feature_np = np.concatenate((query_embed_np, passage_embed_np))\n",
    "                features.append(feature_np)  # Append NumPy array\n",
    "                labels.append(1)\n",
    "                positive_indices.add(passage_idx)\n",
    "        \n",
    "        # Compute cosine similarity on GPU\n",
    "        cos_sim_cp = 1 - cp.matmul(query_embed_cp, all_collection_embeds_cp.T)\n",
    "        top_k_indices = cp.asnumpy(cp.argpartition(cos_sim_cp, subsampling_top_k + len(positive_indices))[:subsampling_top_k + len(positive_indices)])\n",
    "        negative_indices = top_k_indices[:subsampling_top_k]\n",
    "        #print('Query')\n",
    "        #print(queries.iloc[q_idx]['query'])\n",
    "        #print('Passage')\n",
    "        #print(collection.iloc[negative_indices[0]]['passage'])\n",
    "        #print('\\n\\n')\n",
    "\n",
    "        for passage_idx in negative_indices:\n",
    "            passage_embed_cp = all_collection_embeds_cp[passage_idx]\n",
    "\n",
    "            # Convert CuPy arrays back to NumPy\n",
    "            query_embed_np = cp.asnumpy(query_embed_cp)\n",
    "            passage_embed_np = cp.asnumpy(passage_embed_cp)\n",
    "\n",
    "            # Concatenate using NumPy\n",
    "            feature_np = np.concatenate((query_embed_np, passage_embed_np)).astype(np.float16)\n",
    "            features.append(feature_np)  # Append NumPy array\n",
    "            labels.append(0)\n",
    "\n",
    "        # Explicitly free memory if needed\n",
    "        # cp.get_default_memory_pool().free_all_blocks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(calculate_feat):\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16\n"
     ]
    }
   ],
   "source": [
    "print(features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(calculate_feat):\n",
    "    np.save(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'features'), features)\n",
    "    np.save(Config.COMBINED_EMBEDDINGS.replace('{TYPE}', 'labels'), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5034360, 1536)\n",
      "(5034360,)\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Negative labels: 4919000\n",
      "Positive labels: 115360\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(labels[:200])\n",
    "print('Negative labels: ' + str(len(list(filter(lambda x: x == 0, labels)))))\n",
    "print('Positive labels: ' + str(len(list(filter(lambda x: x > 0, labels)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'all_collection_embeds' in locals() and 'all_collection_embeds_cp' in locals():\n",
    "    del all_collection_embeds, all_collection_embeds_cp, all_query_embeds, all_query_embeds_cp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4530924\n",
      "4530924\n",
      "4530924\n",
      "503436\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del features, labels\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "We have too many features and datapoints, which a single SVR can't handle on this machine. Instead, I'm going to:\n",
    "\n",
    "- Train X different SVR using a portion of the rows\n",
    "- Ensemble the SVRs\n",
    "- In that way duplicate the bagging of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create random subsets with overlap\n",
    "def create_subsets(X, y, num_subsets, overlap_percentage):\n",
    "    subsets = []\n",
    "    subset_size = int((len(X) // num_subsets) * overlap_percentage)\n",
    "    num_samples = len(X)\n",
    "    \n",
    "    for _ in range(num_subsets):\n",
    "        subset_indices = np.random.choice(num_samples, size=subset_size, replace=True)\n",
    "        X_subset = X[subset_indices]\n",
    "        y_subset = y[subset_indices]\n",
    "        subsets.append((X_subset, y_subset))\n",
    "        print(f'Done with {_}/{num_subsets}')\n",
    "    \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging function to track progress\n",
    "def log_progress(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    precision = precision_score(y_val, y_pred_binary)\n",
    "    recall = recall_score(y_val, y_pred_binary)\n",
    "    f1 = f1_score(y_val, y_pred_binary)\n",
    "    accuracy = accuracy_score(y_val, y_pred_binary)\n",
    "    \n",
    "    print(f'  Accuracy: {accuracy:.4f}')\n",
    "    print(f'  Precision: {precision:.4f}')\n",
    "    print(f'  Recall: {recall:.4f}')\n",
    "    print(f'  F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize\n",
    "\n",
    "There is no way we fit 200GB of features into the GPU at once to transform the data. Hence, we calculate the fitting on the CPU with the standard scaler, chunk it and then transform in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Chunk: 0/181\n",
      "Doing Chunk: 1/181\n",
      "Doing Chunk: 2/181\n",
      "Doing Chunk: 3/181\n",
      "Doing Chunk: 4/181\n",
      "Doing Chunk: 5/181\n",
      "Doing Chunk: 6/181\n",
      "Doing Chunk: 7/181\n",
      "Doing Chunk: 8/181\n",
      "Doing Chunk: 9/181\n",
      "Doing Chunk: 10/181\n",
      "Doing Chunk: 11/181\n",
      "Doing Chunk: 12/181\n",
      "Doing Chunk: 13/181\n",
      "Doing Chunk: 14/181\n",
      "Doing Chunk: 15/181\n",
      "Doing Chunk: 16/181\n",
      "Doing Chunk: 17/181\n",
      "Doing Chunk: 18/181\n",
      "Doing Chunk: 19/181\n",
      "Doing Chunk: 20/181\n",
      "Doing Chunk: 21/181\n",
      "Doing Chunk: 22/181\n",
      "Doing Chunk: 23/181\n",
      "Doing Chunk: 24/181\n",
      "Doing Chunk: 25/181\n",
      "Doing Chunk: 26/181\n",
      "Doing Chunk: 27/181\n",
      "Doing Chunk: 28/181\n",
      "Doing Chunk: 29/181\n",
      "Doing Chunk: 30/181\n",
      "Doing Chunk: 31/181\n",
      "Doing Chunk: 32/181\n",
      "Doing Chunk: 33/181\n",
      "Doing Chunk: 34/181\n",
      "Doing Chunk: 35/181\n",
      "Doing Chunk: 36/181\n",
      "Doing Chunk: 37/181\n",
      "Doing Chunk: 38/181\n",
      "Doing Chunk: 39/181\n",
      "Doing Chunk: 40/181\n",
      "Doing Chunk: 41/181\n",
      "Doing Chunk: 42/181\n",
      "Doing Chunk: 43/181\n",
      "Doing Chunk: 44/181\n",
      "Doing Chunk: 45/181\n",
      "Doing Chunk: 46/181\n",
      "Doing Chunk: 47/181\n",
      "Doing Chunk: 48/181\n",
      "Doing Chunk: 49/181\n",
      "Doing Chunk: 50/181\n",
      "Doing Chunk: 51/181\n",
      "Doing Chunk: 52/181\n",
      "Doing Chunk: 53/181\n",
      "Doing Chunk: 54/181\n",
      "Doing Chunk: 55/181\n",
      "Doing Chunk: 56/181\n",
      "Doing Chunk: 57/181\n",
      "Doing Chunk: 58/181\n",
      "Doing Chunk: 59/181\n",
      "Doing Chunk: 60/181\n",
      "Doing Chunk: 61/181\n",
      "Doing Chunk: 62/181\n",
      "Doing Chunk: 63/181\n",
      "Doing Chunk: 64/181\n",
      "Doing Chunk: 65/181\n",
      "Doing Chunk: 66/181\n",
      "Doing Chunk: 67/181\n",
      "Doing Chunk: 68/181\n",
      "Doing Chunk: 69/181\n",
      "Doing Chunk: 70/181\n",
      "Doing Chunk: 71/181\n",
      "Doing Chunk: 72/181\n",
      "Doing Chunk: 73/181\n",
      "Doing Chunk: 74/181\n",
      "Doing Chunk: 75/181\n",
      "Doing Chunk: 76/181\n",
      "Doing Chunk: 77/181\n",
      "Doing Chunk: 78/181\n",
      "Doing Chunk: 79/181\n",
      "Doing Chunk: 80/181\n",
      "Doing Chunk: 81/181\n",
      "Doing Chunk: 82/181\n",
      "Doing Chunk: 83/181\n",
      "Doing Chunk: 84/181\n",
      "Doing Chunk: 85/181\n",
      "Doing Chunk: 86/181\n",
      "Doing Chunk: 87/181\n",
      "Doing Chunk: 88/181\n",
      "Doing Chunk: 89/181\n",
      "Doing Chunk: 90/181\n",
      "Doing Chunk: 91/181\n",
      "Doing Chunk: 92/181\n",
      "Doing Chunk: 93/181\n",
      "Doing Chunk: 94/181\n",
      "Doing Chunk: 95/181\n",
      "Doing Chunk: 96/181\n",
      "Doing Chunk: 97/181\n",
      "Doing Chunk: 98/181\n",
      "Doing Chunk: 99/181\n",
      "Doing Chunk: 100/181\n",
      "Doing Chunk: 101/181\n",
      "Doing Chunk: 102/181\n",
      "Doing Chunk: 103/181\n",
      "Doing Chunk: 104/181\n",
      "Doing Chunk: 105/181\n",
      "Doing Chunk: 106/181\n",
      "Doing Chunk: 107/181\n",
      "Doing Chunk: 108/181\n",
      "Doing Chunk: 109/181\n",
      "Doing Chunk: 110/181\n",
      "Doing Chunk: 111/181\n",
      "Doing Chunk: 112/181\n",
      "Doing Chunk: 113/181\n",
      "Doing Chunk: 114/181\n",
      "Doing Chunk: 115/181\n",
      "Doing Chunk: 116/181\n",
      "Doing Chunk: 117/181\n",
      "Doing Chunk: 118/181\n",
      "Doing Chunk: 119/181\n",
      "Doing Chunk: 120/181\n",
      "Doing Chunk: 121/181\n",
      "Doing Chunk: 122/181\n",
      "Doing Chunk: 123/181\n",
      "Doing Chunk: 124/181\n",
      "Doing Chunk: 125/181\n",
      "Doing Chunk: 126/181\n",
      "Doing Chunk: 127/181\n",
      "Doing Chunk: 128/181\n",
      "Doing Chunk: 129/181\n",
      "Doing Chunk: 130/181\n",
      "Doing Chunk: 131/181\n",
      "Doing Chunk: 132/181\n",
      "Doing Chunk: 133/181\n",
      "Doing Chunk: 134/181\n",
      "Doing Chunk: 135/181\n",
      "Doing Chunk: 136/181\n",
      "Doing Chunk: 137/181\n",
      "Doing Chunk: 138/181\n",
      "Doing Chunk: 139/181\n",
      "Doing Chunk: 140/181\n",
      "Doing Chunk: 141/181\n",
      "Doing Chunk: 142/181\n",
      "Doing Chunk: 143/181\n",
      "Doing Chunk: 144/181\n",
      "Doing Chunk: 145/181\n",
      "Doing Chunk: 146/181\n",
      "Doing Chunk: 147/181\n",
      "Doing Chunk: 148/181\n",
      "Doing Chunk: 149/181\n",
      "Doing Chunk: 150/181\n",
      "Doing Chunk: 151/181\n",
      "Doing Chunk: 152/181\n",
      "Doing Chunk: 153/181\n",
      "Doing Chunk: 154/181\n",
      "Doing Chunk: 155/181\n",
      "Doing Chunk: 156/181\n",
      "Doing Chunk: 157/181\n",
      "Doing Chunk: 158/181\n",
      "Doing Chunk: 159/181\n",
      "Doing Chunk: 160/181\n",
      "Doing Chunk: 161/181\n",
      "Doing Chunk: 162/181\n",
      "Doing Chunk: 163/181\n",
      "Doing Chunk: 164/181\n",
      "Doing Chunk: 165/181\n",
      "Doing Chunk: 166/181\n",
      "Doing Chunk: 167/181\n",
      "Doing Chunk: 168/181\n",
      "Doing Chunk: 169/181\n",
      "Doing Chunk: 170/181\n",
      "Doing Chunk: 171/181\n",
      "Doing Chunk: 172/181\n",
      "Doing Chunk: 173/181\n",
      "Doing Chunk: 174/181\n",
      "Doing Chunk: 175/181\n",
      "Doing Chunk: 176/181\n",
      "Doing Chunk: 177/181\n",
      "Doing Chunk: 178/181\n",
      "Doing Chunk: 179/181\n",
      "Doing Chunk: 180/181\n",
      "Doing Chunk: 181/181\n"
     ]
    }
   ],
   "source": [
    "def chunkify(data, chunk_size):\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i + chunk_size]\n",
    "\n",
    "# Initialize a CPU-based StandardScaler\n",
    "cpu_scaler = StandardScaler()\n",
    "\n",
    "# Fit the CPU scaler incrementally on each chunk of X_train\n",
    "chunk_size = 25000\n",
    "count = 0\n",
    "total = len(X_train) // chunk_size\n",
    "for chunk in chunkify(X_train, chunk_size):\n",
    "    print(f'Doing Chunk: {count}/{total}')\n",
    "    cpu_scaler.partial_fit(chunk)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 0/4530924\n",
      "Done with 25000/4530924\n",
      "Done with 50000/4530924\n",
      "Done with 75000/4530924\n",
      "Done with 100000/4530924\n",
      "Done with 125000/4530924\n",
      "Done with 150000/4530924\n",
      "Done with 175000/4530924\n",
      "Done with 200000/4530924\n",
      "Done with 225000/4530924\n",
      "Done with 250000/4530924\n",
      "Done with 275000/4530924\n",
      "Done with 300000/4530924\n",
      "Done with 325000/4530924\n",
      "Done with 350000/4530924\n",
      "Done with 375000/4530924\n",
      "Done with 400000/4530924\n",
      "Done with 425000/4530924\n",
      "Done with 450000/4530924\n",
      "Done with 475000/4530924\n",
      "Done with 500000/4530924\n",
      "Done with 525000/4530924\n",
      "Done with 550000/4530924\n",
      "Done with 575000/4530924\n",
      "Done with 600000/4530924\n",
      "Done with 625000/4530924\n",
      "Done with 650000/4530924\n",
      "Done with 675000/4530924\n",
      "Done with 700000/4530924\n",
      "Done with 725000/4530924\n",
      "Done with 750000/4530924\n",
      "Done with 775000/4530924\n",
      "Done with 800000/4530924\n",
      "Done with 825000/4530924\n",
      "Done with 850000/4530924\n",
      "Done with 875000/4530924\n",
      "Done with 900000/4530924\n",
      "Done with 925000/4530924\n",
      "Done with 950000/4530924\n",
      "Done with 975000/4530924\n",
      "Done with 1000000/4530924\n",
      "Done with 1025000/4530924\n",
      "Done with 1050000/4530924\n",
      "Done with 1075000/4530924\n",
      "Done with 1100000/4530924\n",
      "Done with 1125000/4530924\n",
      "Done with 1150000/4530924\n",
      "Done with 1175000/4530924\n",
      "Done with 1200000/4530924\n",
      "Done with 1225000/4530924\n",
      "Done with 1250000/4530924\n",
      "Done with 1275000/4530924\n",
      "Done with 1300000/4530924\n",
      "Done with 1325000/4530924\n",
      "Done with 1350000/4530924\n",
      "Done with 1375000/4530924\n",
      "Done with 1400000/4530924\n",
      "Done with 1425000/4530924\n",
      "Done with 1450000/4530924\n",
      "Done with 1475000/4530924\n",
      "Done with 1500000/4530924\n",
      "Done with 1525000/4530924\n",
      "Done with 1550000/4530924\n",
      "Done with 1575000/4530924\n",
      "Done with 1600000/4530924\n",
      "Done with 1625000/4530924\n",
      "Done with 1650000/4530924\n",
      "Done with 1675000/4530924\n",
      "Done with 1700000/4530924\n",
      "Done with 1725000/4530924\n",
      "Done with 1750000/4530924\n",
      "Done with 1775000/4530924\n",
      "Done with 1800000/4530924\n",
      "Done with 1825000/4530924\n",
      "Done with 1850000/4530924\n",
      "Done with 1875000/4530924\n",
      "Done with 1900000/4530924\n",
      "Done with 1925000/4530924\n",
      "Done with 1950000/4530924\n",
      "Done with 1975000/4530924\n",
      "Done with 2000000/4530924\n",
      "Done with 2025000/4530924\n",
      "Done with 2050000/4530924\n",
      "Done with 2075000/4530924\n",
      "Done with 2100000/4530924\n",
      "Done with 2125000/4530924\n",
      "Done with 2150000/4530924\n",
      "Done with 2175000/4530924\n",
      "Done with 2200000/4530924\n",
      "Done with 2225000/4530924\n",
      "Done with 2250000/4530924\n",
      "Done with 2275000/4530924\n",
      "Done with 2300000/4530924\n",
      "Done with 2325000/4530924\n",
      "Done with 2350000/4530924\n",
      "Done with 2375000/4530924\n",
      "Done with 2400000/4530924\n",
      "Done with 2425000/4530924\n",
      "Done with 2450000/4530924\n",
      "Done with 2475000/4530924\n",
      "Done with 2500000/4530924\n",
      "Done with 2525000/4530924\n",
      "Done with 2550000/4530924\n",
      "Done with 2575000/4530924\n",
      "Done with 2600000/4530924\n",
      "Done with 2625000/4530924\n",
      "Done with 2650000/4530924\n",
      "Done with 2675000/4530924\n",
      "Done with 2700000/4530924\n",
      "Done with 2725000/4530924\n",
      "Done with 2750000/4530924\n",
      "Done with 2775000/4530924\n",
      "Done with 2800000/4530924\n",
      "Done with 2825000/4530924\n",
      "Done with 2850000/4530924\n",
      "Done with 2875000/4530924\n",
      "Done with 2900000/4530924\n",
      "Done with 2925000/4530924\n",
      "Done with 2950000/4530924\n",
      "Done with 2975000/4530924\n",
      "Done with 3000000/4530924\n",
      "Done with 3025000/4530924\n",
      "Done with 3050000/4530924\n",
      "Done with 3075000/4530924\n",
      "Done with 3100000/4530924\n",
      "Done with 3125000/4530924\n",
      "Done with 3150000/4530924\n",
      "Done with 3175000/4530924\n",
      "Done with 3200000/4530924\n",
      "Done with 3225000/4530924\n",
      "Done with 3250000/4530924\n",
      "Done with 3275000/4530924\n",
      "Done with 3300000/4530924\n",
      "Done with 3325000/4530924\n",
      "Done with 3350000/4530924\n",
      "Done with 3375000/4530924\n",
      "Done with 3400000/4530924\n",
      "Done with 3425000/4530924\n",
      "Done with 3450000/4530924\n",
      "Done with 3475000/4530924\n",
      "Done with 3500000/4530924\n",
      "Done with 3525000/4530924\n",
      "Done with 3550000/4530924\n",
      "Done with 3575000/4530924\n",
      "Done with 3600000/4530924\n",
      "Done with 3625000/4530924\n",
      "Done with 3650000/4530924\n",
      "Done with 3675000/4530924\n",
      "Done with 3700000/4530924\n",
      "Done with 3725000/4530924\n",
      "Done with 3750000/4530924\n",
      "Done with 3775000/4530924\n",
      "Done with 3800000/4530924\n",
      "Done with 3825000/4530924\n",
      "Done with 3850000/4530924\n",
      "Done with 3875000/4530924\n",
      "Done with 3900000/4530924\n",
      "Done with 3925000/4530924\n",
      "Done with 3950000/4530924\n",
      "Done with 3975000/4530924\n",
      "Done with 4000000/4530924\n",
      "Done with 4025000/4530924\n",
      "Done with 4050000/4530924\n",
      "Done with 4075000/4530924\n",
      "Done with 4100000/4530924\n",
      "Done with 4125000/4530924\n",
      "Done with 4150000/4530924\n",
      "Done with 4175000/4530924\n",
      "Done with 4200000/4530924\n",
      "Done with 4225000/4530924\n",
      "Done with 4250000/4530924\n",
      "Done with 4275000/4530924\n",
      "Done with 4300000/4530924\n",
      "Done with 4325000/4530924\n",
      "Done with 4350000/4530924\n",
      "Done with 4375000/4530924\n",
      "Done with 4400000/4530924\n",
      "Done with 4425000/4530924\n",
      "Done with 4450000/4530924\n",
      "Done with 4475000/4530924\n",
      "Done with 4500000/4530924\n",
      "Done with 4525000/4530924\n",
      "Done with 0/503436\n",
      "Done with 25000/503436\n",
      "Done with 50000/503436\n",
      "Done with 75000/503436\n",
      "Done with 100000/503436\n",
      "Done with 125000/503436\n",
      "Done with 150000/503436\n",
      "Done with 175000/503436\n",
      "Done with 200000/503436\n",
      "Done with 225000/503436\n",
      "Done with 250000/503436\n",
      "Done with 275000/503436\n",
      "Done with 300000/503436\n",
      "Done with 325000/503436\n",
      "Done with 350000/503436\n",
      "Done with 375000/503436\n",
      "Done with 400000/503436\n",
      "Done with 425000/503436\n",
      "Done with 450000/503436\n",
      "Done with 475000/503436\n",
      "Done with 500000/503436\n"
     ]
    }
   ],
   "source": [
    "def transform_in_chunks(scaler, data, chunk_size):\n",
    "    count = 0\n",
    "    scaled_data = []\n",
    "    for chunk in chunkify(data, chunk_size):\n",
    "        print(f'Done with {count}/{len(data)}')\n",
    "        chunk_scaled = scaler.transform(chunk)\n",
    "        scaled_data.append(chunk_scaled)\n",
    "        count += chunk_size\n",
    "    return np.vstack(scaled_data)\n",
    "\n",
    "# Transform X_train and X_test in chunks\n",
    "X_train_scaled = transform_in_chunks(cpu_scaler, X_train, chunk_size)\n",
    "X_test_scaled = transform_in_chunks(cpu_scaler, X_test, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "cp.get_default_memory_pool().free_all_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wont work, we dont have that much CUDA memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "#gpu_scaler = cumlStandardScaler()\n",
    "#X_train_scaled = gpu_scaler.fit_transform(X_train)\n",
    "#X_test_scaled = gpu_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 0/35\n",
      "Done with 1/35\n",
      "Done with 2/35\n",
      "Done with 3/35\n",
      "Done with 4/35\n",
      "Done with 5/35\n",
      "Done with 6/35\n",
      "Done with 7/35\n",
      "Done with 8/35\n",
      "Done with 9/35\n",
      "Done with 10/35\n",
      "Done with 11/35\n",
      "Done with 12/35\n",
      "Done with 13/35\n",
      "Done with 14/35\n",
      "Done with 15/35\n",
      "Done with 16/35\n",
      "Done with 17/35\n",
      "Done with 18/35\n",
      "Done with 19/35\n",
      "Done with 20/35\n",
      "Done with 21/35\n",
      "Done with 22/35\n",
      "Done with 23/35\n",
      "Done with 24/35\n",
      "Done with 25/35\n",
      "Done with 26/35\n",
      "Done with 27/35\n",
      "Done with 28/35\n",
      "Done with 29/35\n",
      "Done with 30/35\n",
      "Done with 31/35\n",
      "Done with 32/35\n",
      "Done with 33/35\n",
      "Done with 34/35\n",
      "35\n",
      "207126\n"
     ]
    }
   ],
   "source": [
    "num_subsets = 35\n",
    "subsets = create_subsets(X_train_scaled, y_train, num_subsets, 1.6)\n",
    "\n",
    "print(len(subsets))\n",
    "print(len(subsets[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "cp.get_default_memory_pool().free_all_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train SVR foreach subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_models = []\n",
    "tqdm._instances.clear()\n",
    "numba.cuda.select_device(1)\n",
    "train = True\n",
    "if(os.path.exists('ensemble_svr_models.pkl')):\n",
    "    train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(train):\n",
    "    for i, (X_subset, y_subset) in enumerate(subsets):\n",
    "        print(f'Training SVR model {i+1}/{num_subsets}')\n",
    "        svr = cumlSVR(kernel='rbf')\n",
    "        svr.fit(X_subset.astype(np.float32), y_subset.astype(np.float32))\n",
    "        log_progress(svr, X_subset, y_subset)\n",
    "        svr_models.append(svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ensemble\n",
    "if(train):\n",
    "    ensemble_filename = 'ensemble_svr_models.pkl'\n",
    "    with open(ensemble_filename, 'wb') as file:\n",
    "        pickle.dump(svr_models, file)\n",
    "\n",
    "    print(f'Ensemble of SVR models saved to {ensemble_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of SVR models loaded from file\n"
     ]
    }
   ],
   "source": [
    "# Load the ensemble of models from the file\n",
    "with open('ensemble_svr_models.pkl', 'rb') as file:\n",
    "    loaded_svr_models = pickle.load(file)\n",
    "\n",
    "print('Ensemble of SVR models loaded from file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction method for the ensemble:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(svr_models, X, threshold=0.5, proof=1):\n",
    "    predictions = np.zeros((len(svr_models), len(X)))\n",
    "    \n",
    "    for i, svr in enumerate(svr_models):\n",
    "        predictions[i] = svr.predict(X)\n",
    "    \n",
    "    # Count votes for each sample\n",
    "    votes = np.sum(predictions > threshold, axis=0)\n",
    "    \n",
    "    # If more than half the models predict 1, return 1; otherwise, return 0\n",
    "    final_predictions = (votes >= proof).astype(int)\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the loaded ensemble of SVR models\n",
    "y_pred_binary = ensemble_predict(loaded_svr_models, X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9966\n",
      "Precision: 0.9987\n",
      "Recall: 0.8527\n",
      "F1-score: 0.9199\n",
      "Confusion Matrix:\n",
      "[[491902     13]\n",
      " [  1697   9824]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    491915\n",
      "           1       1.00      0.85      0.92     11521\n",
      "\n",
      "    accuracy                           1.00    503436\n",
      "   macro avg       1.00      0.93      0.96    503436\n",
      "weighted avg       1.00      1.00      1.00    503436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "class_report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(f'Test set accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{class_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Relevant', 'Relevant'], yticklabels=['Not Relevant', 'Relevant'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plotting SVR results (for regression)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(y_test, \u001b[43my_pred\u001b[49m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVR Predictions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([y_test\u001b[38;5;241m.\u001b[39mmin(), y_test\u001b[38;5;241m.\u001b[39mmax()], [y_test\u001b[38;5;241m.\u001b[39mmin(), y_test\u001b[38;5;241m.\u001b[39mmax()], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk--\u001b[39m\u001b[38;5;124m'\u001b[39m, lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerfect Prediction\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVR Predictions vs Actual\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting SVR results (for regression)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.3, label='SVR Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Perfect Prediction')\n",
    "plt.title('SVR Predictions vs Actual')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
